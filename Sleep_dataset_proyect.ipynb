{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### import libraries\n",
    "\n",
    "# format\n",
    "import pandas as pd\n",
    "\n",
    "# plot\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# math\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.linalg import inv, det\n",
    "from numpy.linalg import eig\n",
    "\n",
    "from scipy import stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "The following project documentation was written as work assignment for the module \"Multivariate Analysis\" of the Master in Statistics for Data Science at the Universidad Carlos III de Madrid. It contains the Multivariate Analysis of a Kaggel dataset on Sleep Health and Lifestyle (https://www.kaggle.com/datasets/uom190346a/sleep-health-and-lifestyle-dataset). The work is split into two parts, where in a first part a exploratory data analysis is performed, where required,  data preprocessing steps are performed and a Prinicipal Component Analysis (PCA) is performed. In the second part, based on the learnings of part one, a (XXXXXXXXXXX) is performed to (XXXXXXXXX). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data_raw = pd.read_csv(\"Sleep_health_and_lifestyle_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The dataset at hand is composed out of the collumns shown in the table below. It has been modified compared to the kaggle source data by turning the \"Sleep Disorder\" Variable into a binary variable (yes/no) and by seperating the blood pressure variables into the two variables blood pressure systolic and blood pressure diastolic.\n",
    "\n",
    "| **Variable**                    | **Description**                                                                                              |\n",
    "|---------------------------------|--------------------------------------------------------------------------------------------------------------|\n",
    "| Person ID                       | An identifier for each individual.                                                                           |\n",
    "| Gender                          | The gender of the person (Male/Female).                                                                      |\n",
    "| Age                             | The age of the person in years.                                                                              |\n",
    "| Occupation                      | The occupation or profession of the person.                                                                  |\n",
    "| Sleep Duration (hours)          | The number of hours the person sleeps per day.                                                               |\n",
    "| Quality of Sleep (scale: 1-10)  | A subjective rating of the quality of sleep, ranging from 1 to 10.                                          |\n",
    "| Physical Activity Level (minutes/day) | The number of minutes the person engages in physical activity daily.                               |\n",
    "| Stress Level (scale: 1-10)      | A subjective rating of the stress level experienced by the person, ranging from 1 to 10.                    |\n",
    "| BMI Category                    | The BMI category of the person (e.g., Underweight, Normal, Overweight).                                      |\n",
    "| Blood Pressure (systolic) | The blood pressure measurement of the person (systolic pressure)|\n",
    "| Blood Pressure (diastolic) |  The blood pressure measurement of the person (diastolic pressure)|\n",
    "| Heart Rate (bpm)                | The resting heart rate of the person in beats per minute.                                                    |\n",
    "| Daily Steps                     | The number of steps the person takes per day.                                                                |\n",
    "| Sleep Disorder                  | The presence or absence of a sleep disorder in the person (Binary)|\n",
    "\n",
    "Furthermore some variable renaming and data type modifications are performed. All these preprocessing steps are performed in the following code chunk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Preprocess Data\n",
    "data = data_raw.copy()\n",
    "\n",
    "rename_dict = {\n",
    "    'Person ID':'person_id',\n",
    "    'Gender': 'gender',\n",
    "    'Age':'age',\n",
    "    'Occupation':'occupation',\n",
    "    'Sleep Duration':'sleep_duration',\n",
    "    'Quality of Sleep':'quality_of_sleep',\n",
    "    'Physical Activity Level':'physical_activity_level',\n",
    "    'Stress Level':'stress_level',\n",
    "    'BMI Category':'bmi_category', \n",
    "    'Blood Pressure':'blood_pressure', \n",
    "    'Heart Rate':'heart_rate', \n",
    "    'Daily Steps':'daily_steps',\n",
    "    'Sleep Disorder':'sleep_disorder' \n",
    "}\n",
    "data.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# change dtype\n",
    "data['quality_of_sleep'] = data['quality_of_sleep'].astype(str)\n",
    "data['stress_level'] = data['stress_level'].astype(str)\n",
    "\n",
    "# make sleep disorder binary\n",
    "data['sleep_disorder'] = data['sleep_disorder'].map(lambda x: '1' if x in ['Insomnia','Sleep Apnea'] else '0').astype(str)\n",
    "\n",
    "# split blood pressure into diastolic & systolic\n",
    "data[[\"blood_pressure_systolic\",\"blood_pressure_diastolic\"]] = data[\"blood_pressure\"].str.split('/',expand=True)\n",
    "data[\"blood_pressure_diastolic\"] = pd.to_numeric(data['blood_pressure_diastolic'])\n",
    "data[\"blood_pressure_systolic\"] = pd.to_numeric(data[\"blood_pressure_systolic\"])\n",
    "\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the value counts and the variable description, the numeric and categorical variables are identified and two lists are set up containing the variables for later use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up column lists\n",
    "numeric_variables = ['age','sleep_duration','physical_activity_level','heart_rate','daily_steps','blood_pressure_systolic','blood_pressure_diastolic']\n",
    "categorical_variables = ['gender','occupation','quality_of_sleep','stress_level','bmi_category','sleep_disorder']\n",
    "\n",
    "data.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reviewing the unique values of the identified categorical values, a duplicate in bmi_category for \"Normal\" and \"Normal Weight\" can be identified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[categorical_variables].apply(pd.unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is solved by replacing all instances of \"Normal Weight\" with \"Normal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['bmi_category'] = data['bmi_category'].replace('Normal Weight', 'Normal')\n",
    "data[[\"bmi_category\"]].apply(pd.unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing so concludes the required preprocessing steps and allows to begin with the first part of this project work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Exploratory Analysis and Dimension Reduction via PCA\n",
    "The first part of this work contains the initial exploratory analysis of the dataset as well as a Principal Component Analysis (PCA) of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explortary Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Exploratory Data Analysis contains a general overview of the datasets structure and correlations. To begin, the first 5 rows of the data Set are shown to give a first insight into the structure of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The categorical Variables can be sperated into the following categories with: \n",
    "\n",
    "One Binary variable:\n",
    "- gender\n",
    "- sleep disorder\n",
    "\n",
    "Three ordinal variables: \n",
    "- quality of sleep\n",
    "- stress level\n",
    "- bmi_category\n",
    "\n",
    "And one nominal variables:\n",
    "- occupation\n",
    "\n",
    "Plotting barplots for the categorical variables, beginning with the binary variables of gender and sleep disorder shows an even distribution between male and female and a fairly even distribution between observations with and without sleep disorder. In the meantime, stress level shows a dicrease in observations towards higher stress level, and equally quality of sleep and body mass index (bmi) show a continious decrease in observations for quality of sleep from 8 to 4 and for a bmi categories from normal to obese. Lastly, the variable occupation shows a somewhat uneven distribution of observations between the different occupations, with the two occupations with the individually biggest contribution to the overall dataset are Nurses and Doctors. The bias a potential overrepresentation of the medical field with irregular working ours in shifts can not be futhere anaylzed in this work, but has to be taken into account in later conclusions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Flo - make plots be subplots instead of individual plots\n",
    "\n",
    "### Categorical Values\n",
    "print(\"Categorical Values: \", categorical_variables)\n",
    "\n",
    "#function to create barplot for each categorical variable\n",
    "def pie_bar(data, feature):\n",
    "    fig, axs = plt.subplots(1,1, figsize=(10, 6))\n",
    "    count_values = data[feature].value_counts()\n",
    "    axs.bar(height = count_values.values,x = count_values.index,edgecolor= 'black')\n",
    "    axs.set_xticks(range(len(count_values)))\n",
    "    axs.set_xticklabels(count_values.index, rotation=45, ha='right')\n",
    "    axs.set_title(f\" Bar Plot for {feature}\")\n",
    "# call function\n",
    "for cat in categorical_variables:\n",
    "    pie_bar(data,cat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of the seven numerical variables, all are continious. Plotting histograms and boxplots side by side, two categories emerge: \n",
    "- measured variables\n",
    "- estimated/rounded variables (variables that probably where estimated as part of a questioneer by its participants)\n",
    "\n",
    "For the measured variables age, haert rate and sleep duration, a more or less continious distribution can be identified for age, with while showing variance still is somewhat uniformly distributed in between the limits of around 30 to 60. Furthermore, appears to show three groups with one group having very little sleep (up to 6,5 hours) and one group sleeping for longer times (more than 8 hours) , while in between these two a dip in sleeping time can be observed. As last variable of this group, the heart rate is shown to have the majority of its observations inbetween 65 and 75 with visual hints to a normal distributions, but shows both in histogram and boxplot significant outliers for higher hartrates which will have to be adressed in the preprocessing step. \n",
    "\n",
    "The estimated/rounded variables (physical activity level,  daily steps, blood_pressure_systolic/diastolic) shows a specific characteristic with a back and forth between highs and lows which can be attributed to the way people estimate numeric values in increments, like evaluating the physical activity level (mins/day) mostly in increments of 15 min (half an hour, 45 min, one hour, etc.) The lows inbetween then show observations with more specific anwser like 42 min, leading to the somewhat irregular apperance of the histograms. Taking this into account, the phyiscal activity level shows a fairly uniform distribution of observation, while dailty steps tends more into the direction of a right skewed uniform distribution, leading to an overall potentially above average fit sample of people. The high percentage of medical workers with a great walking distances as part of their profession might further contribute to this. Meanwhile, the blood preassure systolic/diastolic appears to both be more or less evenly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add x axis label, turn into two big plots\n",
    "\n",
    "# function for histogram + boxplots on numerical variables\n",
    "def hist_box_plot(data, feature):\n",
    "    fig, axs = plt.subplots(1,2, figsize=(10, 5))\n",
    "    axs[0].hist(data[feature],bins=10,density=True,alpha=0.6,color='b',edgecolor=\"black\")\n",
    "    axs[0].set_title(f\"Hist of {feature}\")\n",
    "    axs[1].boxplot(data[feature],vert=True, patch_artist=True,medianprops=dict(color=\"black\"))\n",
    "    axs[1].set_title(f\"Boxplot of {feature}\")\n",
    "    plt.tight_layout(pad=2.0)\n",
    "\n",
    "# call function\n",
    "for numeric_variable in numeric_variables:\n",
    "    hist_box_plot(data,numeric_variable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a first attempt to evaluate the correlations found in this dataset, the following set of Metrics is applied and plotted.\n",
    "\n",
    "$$\n",
    "q_1 = \\left(1 - \\frac{\\min \\lambda_j}{\\max \\lambda_j} \\right)^{p+2}, \\quad\n",
    "$$\n",
    "$$\n",
    "q_2 = 1 - \\frac{p}{\\sum_{j=1}^p (1/\\lambda_j)}, \\quad\n",
    "$$\n",
    "$$\n",
    "q_3 = 1 - \\sqrt{|R|}, \\quad\n",
    "$$\n",
    "$$\n",
    "q_4 = \\left(\\frac{\\max \\lambda_j}{p} \\right)^{3/2}, \\quad\n",
    "$$\n",
    "$$\n",
    "q_5 = \\left(1 - \\frac{\\min \\lambda_j}{p} \\right)^5, \\quad\n",
    "$$\n",
    "$$\n",
    "q_6 = \\sum_{j=1}^p \\frac{1 - 1/r_{ij}}{p}\n",
    "$$\n",
    "\n",
    "The resulting plot shows high correlation metric scores for all metric except for metric 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Statistical Analysis & intercorrelation\n",
    "\n",
    "means = data[numeric_variables].mean()\n",
    "variances = data[numeric_variables].var()\n",
    "df_covariance_matrix = data[numeric_variables].cov()\n",
    "df_correlation_matrix = data[numeric_variables].corr()\n",
    "\n",
    "def intercorrelations(X,categorical_filter = \"whole Dataset\"):\n",
    "    n, p = X.shape\n",
    "    R = np.corrcoef(X, rowvar=False)\n",
    "    lambda_vals, _ = eig(R)\n",
    "    rjj = np.diag(inv(R))\n",
    "    q = np.zeros(6)\n",
    "    q[0] = (1 - min(lambda_vals) / max(lambda_vals)) ** (p + 2)\n",
    "    q[1] = 1 - p / np.sum(1. / lambda_vals)\n",
    "    q[2] = 1 - np.sqrt(det(R))\n",
    "    q[3] = (max(lambda_vals) / p) ** (3 / 2)\n",
    "    q[4] = (1 - min(lambda_vals) / p) ** 5\n",
    "    q[5] = np.sum((1 - 1. / rjj) / p)\n",
    "    \n",
    "    # print\n",
    "    print(q)\n",
    "\n",
    "    # plot\n",
    "    plt.plot(range(1, 7), q, marker='o', linestyle='-', color='b', label='Intercorrelations')\n",
    "    plt.xlabel(\"intercorrelation metric\")\n",
    "    plt.ylabel(\"intercorrelation score\")\n",
    "    plt.suptitle(\"Intercorrelation Metric for filter: \"+categorical_filter)\n",
    "    return None\n",
    "\n",
    "\n",
    "intercorrelations(data[numeric_variables])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying the same method to a dataset filtered on the binary variable sleep disorder shows an overall higher than before correlation in the subset for (??????) while the subset for (???????) shows lower correlation metrics than the joined dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Color the two plots by category\n",
    "\n",
    "#intercorrelation by category function\n",
    "def inter_by_category(df,cat):\n",
    "    count_values = df[cat].value_counts().index\n",
    "    for i in count_values:\n",
    "        aux_data = df[df[cat]==i]\n",
    "        intercorrelations(aux_data[numeric_variables],categorical_filter=cat)\n",
    "\n",
    "inter_by_category(data,'sleep_disorder')\n",
    "\n",
    "# inter_by_category(data,'stress_level')\n",
    "# inter_by_category(data,'stress_level')\n",
    "# inter_by_category(data,'bmi_category')\n",
    "# inter_by_category(data,'sleep_disorder')\n",
    "# inter_by_category(data,'quality_of_sleep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expandning the coreelation analysis with a paiplot shows a veriaty of potential correlations between variables, the most notable being between the linear correlation betwen blood pressure systolic and diastolic as well as between daily steps and heart rate/ blood pressure. Further correlation can bee seen inbetween physical activity level and sleep duration while the plot age vs sleep duration appears to show certain clusters that may be further analyzed in the second part of this work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairplot\n",
    "sns.pairplot(data[numeric_variables], diag_kind='kde', corner=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the correlation corresponding matrix reflects some of the observations made in the pairplot, with the verious near 100% correlation between blood pressure systolic and diastolic very aparent. Two previously less apparent correlations are the ones between age and blood pressure as well as the correlation between physical activity and daily steps. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_mat = data[numeric_variables].corr()\n",
    "plt.figure(figsize=(8, 6))  # Adjust the figure size as needed\n",
    "sns.heatmap(corr_mat, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, square=True, linewidths=0.5)\n",
    "plt.title('Correlation Plot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the covariance matrix however shows an issue with the current format of the data, where daily steps outweighs all other variances due to its scale (3000 - 10000). This issue will be adressed in the next section of part one of this work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cov_plot(data,numeric_variables):\n",
    "    corr_mat = data[numeric_variables].cov()\n",
    "    plt.figure(figsize=(8, 6))  # Adjust the figure size as needed\n",
    "    sns.heatmap(corr_mat, annot=True, cmap='coolwarm', square=True, linewidths=0.5)\n",
    "    plt.title('Covariance Matrix')\n",
    "    plt.show()\n",
    "\n",
    "cov_plot(data,numeric_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a general overview of structure and correlation in the data, the next step is to scaling and outlier issues in the next subsection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function for plotting of conditional histograms \n",
    "# def plot_categorical_hist(data,\n",
    "#                           ncols,\n",
    "#                           numeric_variables,\n",
    "#                           categorical_variables,\n",
    "#                           host_stat='count',\n",
    "#                           figsize=(12, 10)\n",
    "#                           ):\n",
    "    \n",
    "#     nrows = math.ceil(len(numeric_variables)/ncols)\n",
    "#     fig, axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "#     for i, col in enumerate(numeric_variables):\n",
    "#         row = i // 2 \n",
    "#         col_pos = i % 2 \n",
    "#         sns.histplot(data=data, x=col, bins=10,hue=categorical_variables, kde=True, ax=axes[row, col_pos],stat=host_stat)\n",
    "#         axes[row, col_pos].set_title(f'Distribution of {col}')\n",
    "\n",
    "#     # Adjust layout for better spacing\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # TODO: Select relevant ones \n",
    "# for categorical_variable in categorical_variables:\n",
    "#     print(categorical_variable)\n",
    "#     plot_categorical_hist(data=data,\n",
    "#                           ncols=2,\n",
    "#                           numeric_variables=numeric_variables,\n",
    "#                           categorical_variables=categorical_variable,\n",
    "#                           host_stat='probability',\n",
    "#                           figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "The following two issues in the current data set: \n",
    "- Outliers in variable \"heart rate\"\n",
    "- Scaling issue to (among others) variable \"daily steps\"\n",
    "\n",
    "This section corrects outliers, validates skewness and standardizes the numeric variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers and Skewness\n",
    "\n",
    "The aim of this part of the preprocessing, is to obtain symmetric variables without outliers in order to apply in a correct form the PCA. \n",
    "\n",
    "It is observed that only one variable has outliers and positive skewness problems (heart rate). Therefore, the first step is to cut the outliers (4% of the dataframe), and then, check if the skewness problem is also corrected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print skewness\n",
    "for i in numeric_variables:\n",
    "    aux_skew = stats.skew(data[i])\n",
    "    print(f\"Skewness of {i} : {aux_skew}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_stats = []\n",
    "\n",
    "for i in numeric_variables:\n",
    "    # Compute the descriptive statistics using scipy.stats.describe\n",
    "    description = stats.describe(data[i])\n",
    "    p90 = np.percentile(data[i], 90)\n",
    "    p95 = np.percentile(data[i], 95)\n",
    "    p99 = np.percentile(data[i], 99)\n",
    "\n",
    "    # Store the results as a dictionary (with variable name as key)\n",
    "    summary_stats.append({\n",
    "        'Variable': i,\n",
    "        'Count': description.nobs,\n",
    "        'Min': description.minmax[0],\n",
    "        'Mean': description.mean,\n",
    "        'Percentile 90%': p90,\n",
    "        'Percentile 95%': p95,\n",
    "        'Percentile 99%': p99,\n",
    "        'Max': description.minmax[1],\n",
    "        'Variance': description.variance\n",
    "    })\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame for easier display\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "\n",
    "# Display the summary statistics table\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in numeric_variables:\n",
    "    q1 = np.percentile(data[i], 25)\n",
    "    q3 = np.percentile(data[i], 75)\n",
    "    RIC = q3 - q1 \n",
    "    nout = np.sum(data[i] > (q3 + 1.5*RIC))\n",
    "    print(f\"The threshold for {i} upper outliers is  {q3 + 1.5*RIC}\")\n",
    "    print(f\" then there are {nout} outliers in this variable, representing the {np.round(nout/374*100,2)} % of the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the skewness was also corrected by cutting the oultiers observations. For that reason, there is not needed another type of transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temporary data while we have all the transformations\n",
    "data_cut = data[data['heart_rate'] < 78] \n",
    "\n",
    "# CHECKING SKEWNESS AFTER CUTTING OUTLIERS\n",
    "aux_skew = stats.skew(data_cut[\"heart_rate\"])\n",
    "print(f\"Skewness of heart_rate : {aux_skew}\")\n",
    "\n",
    "# plot hist % boxplot before and after\n",
    "hist_box_plot(data,\"heart_rate\")\n",
    "hist_box_plot(data_cut,\"heart_rate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize numeric variables\n",
    "\n",
    "Having seen in the exploratory data analysis that there exists a strong imbalance in scale between numerical variables in the dataset, the dataset is standardized in this step to mean 0 and scaled on its standarddeviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "data_standardized_numeric = (data_cut[numeric_variables] - data_cut[numeric_variables].mean()) / data_cut[numeric_variables].std()\n",
    "data_standardized = pd.concat([data_standardized_numeric,data_cut[categorical_variables]], axis =1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the boxplots pre-standardized and post-standardized shows the major impact the rescaling has, where daily steps previously dominated and now an even distribution for all numeric variables can be seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "fig, axs = plt.subplots(1,2, figsize=(10, 5))\n",
    "axs[0].boxplot(data[numeric_variables],vert=True, patch_artist=True,medianprops=dict(color=\"black\"))\n",
    "axs[0].set_xticklabels(numeric_variables, rotation=45, ha=\"right\")\n",
    "axs[1].boxplot(data_standardized_numeric[numeric_variables],vert=True, patch_artist=True,medianprops=dict(color=\"black\"))\n",
    "axs[1].set_xticklabels(numeric_variables, rotation=45, ha=\"right\")\n",
    "fig.suptitle(\"Boxplots not-standardized vs standardized\", fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result from scaling, now the covariance matrix can be constructed, showing similar results compared to the previously analyzed correlation matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_plot(data_standardized,numeric_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "Having analyzed the data and its characteristic and highly correlated variables identified, as well as having eliminated outliers as well as having standardized the numeric variables, principal component analysis can now be applied in an attempt to reduce dimensionality. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Principal Components\n",
    "\n",
    "By analysing the Explained Variance (eigenvalues) trend, and the Joliffe´s and Kaiser´s criterion, for this project there are selected 3 Principal components that explain the 90\\% of the variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pca = data_standardized[numeric_variables]\n",
    "pca = PCA()\n",
    "pca.fit(data_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_val = pca.explained_variance_\n",
    "print(\"Explained Variance: \", eig_val)\n",
    "\n",
    "sv = pca.singular_values_\n",
    "print(\"Singular Values: \", sv)\n",
    "\n",
    "#----------------------- JUST CHECKING MATHS -----------------------\n",
    "singular_values_squared = sv ** 2\n",
    "# Compare singular values squared vs eigenvalues\n",
    "#normalized_singular_values_squared = singular_values_squared / (X_scaled.shape[0] - 1)\n",
    "#print(\"Eigenvalues (Explained Variance):\", eig_val)\n",
    "#print(\"Singular Values Squared (Normalized):\", normalized_singular_values_squared)\n",
    "#--------------------------------------------------------------------------------\n",
    "\n",
    "# Covariance Matrix\n",
    "S = np.cov(data_pca, rowvar=False)\n",
    "print(\"trace: \", S.trace())\n",
    "\n",
    "# Kaiser´s criterion\n",
    "mean_eig = S.trace()/7\n",
    "\n",
    "# Jollife´s criterion\n",
    "joliffe = 0.7 * S.trace()/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(eig_val, marker = 'o', linestyle = '-', color = 'g')\n",
    "plt.axhline(y=mean_eig, color='r', linestyle='--', label='Keisers Criterion')\n",
    "plt.axhline(y=joliffe, color='r', linestyle='-', label='Jollife Criterion')\n",
    "plt.title(\"Explained Variance\")\n",
    "plt.xlabel(\"Principal Component\")\n",
    "plt.ylabel(\"Eigen Values\")\n",
    "\n",
    "# Change xlabels\n",
    "tick_positions = [0, 1, 2, 3, 4, 5, 6]\n",
    "custom_labels = ['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6', 'PC7']  \n",
    "\n",
    "# Set custom x-ticks with custom labels\n",
    "plt.xticks(ticks=tick_positions, labels=custom_labels)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# I AM STILL CHECKING THIS ONE, ONLY TRUST 100% THE ONE THAT IS ABOVE\n",
    "\n",
    "\n",
    "# Explained variance ratio\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "cumulative_explained_variance = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Show the cumulative explained variance\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance, marker='o', color='g')\n",
    "plt.axvline(x=3, color='r', linestyle='--', label='Keisers Criterion')\n",
    "plt.title(\"Cumulative Explained Variance\")\n",
    "plt.xlabel(\"Principal Component Index\")\n",
    "plt.ylabel(\"Cumulative Explained Variance Ratio\")\n",
    "\n",
    "# Adding labels next to the points\n",
    "for i, (x, y) in enumerate(zip(range(1, len(cumulative_explained_variance) + 1), cumulative_explained_variance)):\n",
    "    plt.text(x, y, f'{y:.2f}', horizontalalignment='right', verticalalignment='bottom', fontsize=10)\n",
    "\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
